{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentinel 2 Spatial Data\n",
    "Download spatial data and calculate vegetation index\n",
    "\n",
    "Source:\n",
    "- [Planetary Computer](https://planetarycomputer.microsoft.com/docs/overview/about)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:10.630183Z",
     "iopub.status.busy": "2022-06-07T18:07:10.630183Z",
     "iopub.status.idle": "2022-06-07T18:07:10.637182Z",
     "shell.execute_reply": "2022-06-07T18:07:10.636183Z",
     "shell.execute_reply.started": "2022-06-07T18:07:10.630183Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:10.639183Z",
     "iopub.status.busy": "2022-06-07T18:07:10.638183Z",
     "iopub.status.idle": "2022-06-07T18:07:16.616336Z",
     "shell.execute_reply": "2022-06-07T18:07:16.616336Z",
     "shell.execute_reply.started": "2022-06-07T18:07:10.638183Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipyleaflet\n",
    "\n",
    "import planetary_computer as pc\n",
    "\n",
    "import pystac_client\n",
    "import geopandas as gpd\n",
    "from satstac import Item, ItemCollection\n",
    "import intake_stac\n",
    "\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import xarray\n",
    "\n",
    "import dask\n",
    "from dask import compute, delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "import datetime\n",
    "import calendar\n",
    "import re\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:17:34.796906Z",
     "iopub.status.busy": "2022-06-07T18:17:34.796906Z",
     "iopub.status.idle": "2022-06-07T18:17:42.045129Z",
     "shell.execute_reply": "2022-06-07T18:17:42.035550Z",
     "shell.execute_reply.started": "2022-06-07T18:17:34.796906Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = Client(n_workers=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:21.897656Z",
     "iopub.status.busy": "2022-06-07T18:07:21.897656Z",
     "iopub.status.idle": "2022-06-07T18:07:21.928907Z",
     "shell.execute_reply": "2022-06-07T18:07:21.928907Z",
     "shell.execute_reply.started": "2022-06-07T18:07:21.897656Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PARAMETER DEFINITION\n",
    "BASE_DIR = \"./data/monthly ndvi\"\n",
    "AOI = \"Schwarzwald\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Planetary Computer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:21.928907Z",
     "iopub.status.busy": "2022-06-07T18:07:21.928907Z",
     "iopub.status.idle": "2022-06-07T18:07:32.762345Z",
     "shell.execute_reply": "2022-06-07T18:07:32.762345Z",
     "shell.execute_reply.started": "2022-06-07T18:07:21.928907Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentinel-1-grd            \t- Sentinel 1 Level-1 Ground Range Detected (GRD)\n",
      "sentinel-1-rtc            \t- Sentinel 1 Radiometrically Terrain Corrected (RTC)\n",
      "landsat-8-c2-l2           \t- Landsat 8 Collection 2 Level-2\n",
      "sentinel-2-l2a            \t- Sentinel-2 Level-2A\n",
      "landsat-c2-l1             \t- Landsat Collection 2 Level-1\n",
      "landsat-c2-l2             \t- Landsat Collection 2 Level-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>gsd</th>\n",
       "      <th>common_name</th>\n",
       "      <th>center_wavelength</th>\n",
       "      <th>full_width_half_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOT</td>\n",
       "      <td>aerosol optical thickness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01</td>\n",
       "      <td>coastal aerosol</td>\n",
       "      <td>60.0</td>\n",
       "      <td>coastal</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02</td>\n",
       "      <td>visible blue</td>\n",
       "      <td>10.0</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B03</td>\n",
       "      <td>visible green</td>\n",
       "      <td>10.0</td>\n",
       "      <td>green</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B04</td>\n",
       "      <td>visible red</td>\n",
       "      <td>10.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B05</td>\n",
       "      <td>vegetation classification red edge</td>\n",
       "      <td>20.0</td>\n",
       "      <td>rededge</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B06</td>\n",
       "      <td>vegetation classification red edge</td>\n",
       "      <td>20.0</td>\n",
       "      <td>rededge</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B07</td>\n",
       "      <td>vegetation classification red edge</td>\n",
       "      <td>20.0</td>\n",
       "      <td>rededge</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B08</td>\n",
       "      <td>near infrared</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nir</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B8A</td>\n",
       "      <td>vegetation classification red edge</td>\n",
       "      <td>20.0</td>\n",
       "      <td>rededge</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B09</td>\n",
       "      <td>water vapor</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B11</td>\n",
       "      <td>short-wave infrared, snow/ice/cloud classifica...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>swir16</td>\n",
       "      <td>1.610</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B12</td>\n",
       "      <td>short-wave infrared, snow/ice/cloud classifica...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>swir22</td>\n",
       "      <td>2.190</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                        description   gsd common_name  \\\n",
       "0   AOT                          aerosol optical thickness   NaN         NaN   \n",
       "1   B01                                    coastal aerosol  60.0     coastal   \n",
       "2   B02                                       visible blue  10.0        blue   \n",
       "3   B03                                      visible green  10.0       green   \n",
       "4   B04                                        visible red  10.0         red   \n",
       "5   B05                 vegetation classification red edge  20.0     rededge   \n",
       "6   B06                 vegetation classification red edge  20.0     rededge   \n",
       "7   B07                 vegetation classification red edge  20.0     rededge   \n",
       "8   B08                                      near infrared  10.0         nir   \n",
       "9   B8A                 vegetation classification red edge  20.0     rededge   \n",
       "10  B09                                        water vapor  60.0         NaN   \n",
       "11  B11  short-wave infrared, snow/ice/cloud classifica...  20.0      swir16   \n",
       "12  B12  short-wave infrared, snow/ice/cloud classifica...  20.0      swir22   \n",
       "\n",
       "    center_wavelength  full_width_half_max  \n",
       "0                 NaN                  NaN  \n",
       "1               0.443                0.027  \n",
       "2               0.490                0.098  \n",
       "3               0.560                0.045  \n",
       "4               0.665                0.038  \n",
       "5               0.704                0.019  \n",
       "6               0.740                0.018  \n",
       "7               0.783                0.028  \n",
       "8               0.842                0.145  \n",
       "9               0.865                0.033  \n",
       "10              0.945                0.026  \n",
       "11              1.610                0.143  \n",
       "12              2.190                0.242  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get catalog from planetary computer\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1/\")\n",
    "\n",
    "# explre available collections on planetary computer\n",
    "collections = catalog.get_children()\n",
    "for collection in collections:\n",
    "    if 'landsat' in collection.title.lower() or 'sentinel' in collection.title.lower():\n",
    "        print(f\"{collection.id:<25} \\t- {collection.title}\")\n",
    "        \n",
    "COLLECTION = \"sentinel-2-l2a\"\n",
    "\n",
    "collection_childs = catalog.get_child(COLLECTION)\n",
    "bands = pd.json_normalize(collection_childs.extra_fields[\"summaries\"][\"eo:bands\"])\n",
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Area of Interest\n",
    "Download data that intersects with AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:32.777977Z",
     "iopub.status.busy": "2022-06-07T18:07:32.777977Z",
     "iopub.status.idle": "2022-06-07T18:07:33.918464Z",
     "shell.execute_reply": "2022-06-07T18:07:33.855960Z",
     "shell.execute_reply.started": "2022-06-07T18:07:32.777977Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7.644971139915396, 47.544726784957334),\n",
       " (8.836878965890259, 48.9728217552738)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf = gpd.read_file(f\"./data/ThuenenGeoLocations/geolocations_aoi.geojson\")\n",
    "\n",
    "geodf_aoi = geodf.loc[geodf[\"bez_wg_bu\"] == AOI].iloc[0]\n",
    "\n",
    "def bounding_box(points):\n",
    "    x_coordinates, y_coordinates = zip(*points)\n",
    "\n",
    "    return [(min(x_coordinates), min(y_coordinates)), (max(x_coordinates), max(y_coordinates))]\n",
    "\n",
    "# bbounding box to get data for\n",
    "points = [point for point in geodf_aoi[\"geometry\"].exterior.coords]\n",
    "bbox = bounding_box(points)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:33.934085Z",
     "iopub.status.busy": "2022-06-07T18:07:33.918464Z",
     "iopub.status.idle": "2022-06-07T18:07:34.090335Z",
     "shell.execute_reply": "2022-06-07T18:07:34.074710Z",
     "shell.execute_reply.started": "2022-06-07T18:07:33.934085Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "\n",
    "def transform_epsg_32632_from_4326(xy):\n",
    "    \"\"\"EPSG 32632 from 4326\"\"\"\n",
    "    inProj = Proj(init='epsg:4326')\n",
    "    outProj = Proj(init='epsg:32632')\n",
    "    x, y = transform(inProj, outProj, xy[0], xy[1])\n",
    "    return x, y\n",
    "\n",
    "def transform_epsg_32632_to_4326(xy):\n",
    "    \"\"\"EPSG 32632 from 4326\"\"\"\n",
    "    inProj = Proj(init='epsg:32632')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "    x, y = transform(inProj, outProj, xy[0], xy[1])\n",
    "    return x, y\n",
    "\n",
    "BBOX_32632 = list()\n",
    "BBOX_32632.append(transform_epsg_32632_from_4326(bbox[0]))\n",
    "BBOX_32632.append(transform_epsg_32632_from_4326(bbox[1]))\n",
    "\n",
    "# bbox to search data for\n",
    "BBOX_SEARCH = (bbox[0][0], bbox[0][1], bbox[1][0], bbox[1][1]) # from Blackforest shape import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### BBOX Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(scroll_wheel_zoom=False, center=(geodf_aoi[\"geometry\"].centroid.xy[1][0], geodf_aoi[\"geometry\"].centroid.xy[0][0]), zoom=7.25, height=\"400px\")\n",
    "\n",
    "# add controls\n",
    "m.add_control(ipyleaflet.ScaleControl(position=\"bottomleft\"))\n",
    "m.add_control(ipyleaflet.FullScreenControl())\n",
    "\n",
    "# define polygon\n",
    "polygon_coords = np.array(geodf_aoi[\"geometry\"].exterior.coords.xy)\n",
    "polygon_locations = list()\n",
    "for i in range(0, len(polygon_coords[1])):\n",
    "    polygon_locations.append((polygon_coords[1][i], polygon_coords[0][i]))\n",
    "\n",
    "polygon = ipyleaflet.Polygon(\n",
    "    locations=polygon_locations,\n",
    "    color=\"green\",\n",
    "    fill_color=\"green\"\n",
    ")\n",
    "m.add_layer(polygon)\n",
    "\n",
    "# define bbox around polygon\n",
    "rectangle = ipyleaflet.Rectangle(bounds=((bbox[0][1], bbox[0][0]), (bbox[1][1], bbox[1][0])), color=\"blue\", weight=3, fill_opacity=0)\n",
    "m.add_layer(rectangle)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Identify Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:34.484416Z",
     "iopub.status.busy": "2022-06-07T18:07:34.483415Z",
     "iopub.status.idle": "2022-06-07T18:07:36.755596Z",
     "shell.execute_reply": "2022-06-07T18:07:36.755596Z",
     "shell.execute_reply.started": "2022-06-07T18:07:34.484416Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles of interest for selected area: 32TLT 32TMT 32ULU 32UMU 32UMV\n"
     ]
    }
   ],
   "source": [
    "time_range = \"2016-05-01/2016-08-31\"\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[COLLECTION], \n",
    "    bbox=BBOX_SEARCH, \n",
    "    datetime=time_range\n",
    ")\n",
    "\n",
    "# save search results into geojson file\n",
    "search.get_all_items().save_object(f\"{BASE_DIR}/GeoJSON/{AOI}_all_tiles.geojson\")\n",
    "# load geojson file to get all attributes\n",
    "gf = gpd.read_file(f\"{BASE_DIR}/GeoJSON/{AOI}_all_tiles.geojson\")\n",
    "\n",
    "tiles = gf.groupby(\"s2:mgrs_tile\").agg({\"geometry\": lambda x:x.value_counts().index[0]}).reset_index()\n",
    "for _i, tile in tiles.iterrows():\n",
    "    polygon_coords = np.array(tile.geometry.exterior.coords.xy)\n",
    "    polygon_locations = list()\n",
    "    for i in range(0, len(polygon_coords[1])):\n",
    "        polygon_locations.append((polygon_coords[1][i], polygon_coords[0][i]))\n",
    "\n",
    "    # build rectangle\n",
    "    polygon_tile = ipyleaflet.Polygon(\n",
    "        locations=polygon_locations,\n",
    "        color=\"red\",\n",
    "        weight=2,\n",
    "        fill_opacity=0\n",
    "    )\n",
    "    # plot rectangle as new layer on map\n",
    "    m.add_layer(polygon_tile)\n",
    "\n",
    "# tiles that needs to be fetched as they interact with bbox of AOI\n",
    "TILES_OF_INTEREST = list(tiles.loc[tiles.intersects(geodf_aoi[\"geometry\"])][\"s2:mgrs_tile\"].unique())\n",
    "print(f\"Tiles of interest for selected area: {' '.join(TILES_OF_INTEREST)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preparation\n",
    "- Download data\n",
    "- Remove clouds\n",
    "- Calculate vegetation index\n",
    "- Save data by month\n",
    "- Combine data by year\n",
    "- Clip AOI\n",
    "- Save AOI\n",
    "\n",
    "parallize using DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T18:07:37.093599Z",
     "iopub.status.busy": "2022-06-07T18:07:37.093599Z",
     "iopub.status.idle": "2022-06-07T18:07:37.165601Z",
     "shell.execute_reply": "2022-06-07T18:07:37.161599Z",
     "shell.execute_reply.started": "2022-06-07T18:07:37.093599Z"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_scenes(month: str, year: str, bbox: tuple)->pystac_client.item_search.ItemSearch:\n",
    "    last_month_day = calendar.monthrange(int(year), int(month))[-1]\n",
    "    time_range = f\"{year}-{month}-01/{year}-{month}-{last_month_day}\"\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[COLLECTION], \n",
    "        bbox=bbox, \n",
    "        datetime=time_range\n",
    "    )\n",
    "\n",
    "    search.get_all_items().save_object(f\"{BASE_DIR}/GeoJSON/{AOI}_{month}_{year}.geojson\")\n",
    "\n",
    "    print(\"-\"*75)\n",
    "    print(f'Total: {len([i for i in search.get_items()])} matches for {month}-{year}')\n",
    "    print(\"-\"*75)\n",
    "    return search\n",
    "\n",
    "@dask.delayed\n",
    "def calc_vegetation_index(intake_stac_scene: intake_stac.catalog.StacItem)->(xarray.Dataset, str):\n",
    "    try:\n",
    "        if os.path.exists(f\"{BASE_DIR}/scenes/{intake_stac_scene.name}.nc\"):\n",
    "            ds = xarray.open_dataset(f\"{BASE_DIR}/scenes/{intake_stac_scene.name}.nc\", decode_coords=\"all\").rio.write_crs(32632)\n",
    "        else:\n",
    "            # Create DataArray using Raster data from RED and NIR band\n",
    "            da_red = rioxarray.open_rasterio(pc.sign(intake_stac_scene.B04.metadata[\"href\"]))\n",
    "            da_nir = rioxarray.open_rasterio(pc.sign(intake_stac_scene.B08.metadata[\"href\"]))\n",
    "            scl = rioxarray.open_rasterio(pc.sign(intake_stac_scene.SCL.metadata[\"href\"]))\n",
    "\n",
    "            scl_high = scl.reindex(x=da_nir.x, y=da_nir.y, method='nearest')\n",
    "            no_cloud_map = (scl_high[0] != 8) & (scl_high[0] != 9) & (scl_high[0] != 10) & (scl_high[0] != 3)\n",
    "\n",
    "            # Calculate NDVI from float32 (f4) arrays\n",
    "            nir_values = da_nir.values[0].astype('f4')\n",
    "            red_values = da_red.values[0].astype('f4')\n",
    "            ndvi = (nir_values - red_values) / (nir_values + red_values)\n",
    "            evi2 = 2.5 * (nir_values - red_values) / (nir_values + 2.4 * red_values + 1.0)\n",
    "            # include nan after these have been lost due to evi2 calculation\n",
    "            evi2 = np.where(~np.isnan(ndvi), evi2, np.nan)\n",
    "            \n",
    "            ds = xarray.Dataset(\n",
    "                data_vars=dict(\n",
    "                    ndvi=([\"x\", \"y\"], np.where(no_cloud_map, ndvi, np.nan)),\n",
    "                    evi2=([\"x\", \"y\"], np.where(no_cloud_map, evi2, np.nan))\n",
    "                ),\n",
    "                coords=dict(\n",
    "                    x=([\"x\"], da_nir.x.values),\n",
    "                    y=([\"y\"], da_nir.y.values)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            #ds = ds.rio.write_crs(int(str(da_nir.rio.crs).split(\":\")[-1]))\n",
    "            ds = ds.rio.write_crs(32632)\n",
    "            \n",
    "            #if intake_stac_scene.metadata[\"date\"].month == 5 and intake_stac_scene.metadata[\"date\"].year == 2016:\n",
    "            #    ds.to_netcdf(f\"{BASE_DIR}/scenes/{intake_stac_scene.name}.nc\", 'w', engine='netcdf4')\n",
    "\n",
    "            # return dataset with ndvi and evi2 and scene date\n",
    "            del ndvi, evi2, da_red, da_nir, nir_values, red_values, scl, scl_high, no_cloud_map\n",
    "        \n",
    "        # rio clip bounding box\n",
    "        ds = ds.rio.clip_box(\n",
    "            minx=BBOX_32632[0][0],\n",
    "            miny=BBOX_32632[0][1],\n",
    "            maxx=BBOX_32632[1][0],\n",
    "            maxy=BBOX_32632[1][1],\n",
    "        )\n",
    "        \n",
    "        return ds, intake_stac_scene.metadata[\"date\"]\n",
    "    except (rasterio.RasterioIOError):\n",
    "        return None, None\n",
    "    \n",
    "def process_scenes(intakeStacItemCollection: intake_stac.catalog.StacItemCollection)->xarray.Dataset:\n",
    "    #scenes = []\n",
    "    date_scenes = []\n",
    "    ds_scenes = []\n",
    "\n",
    "    delayed_tasks = []\n",
    "    for s in range(len(list(intakeStacItemCollection))):\n",
    "        print(f'Current scene ({s}) {list(intakeStacItemCollection)[s]} started at {str(datetime.datetime.now())}')\n",
    "        delayed_tasks.append(calc_vegetation_index(intakeStacItemCollection[list(intakeStacItemCollection)[s]]))\n",
    "    \n",
    "    processed_index = compute(*delayed_tasks)\n",
    "    \n",
    "    ds_scenes, date_scenes = zip(*processed_index)\n",
    "\n",
    "    ds_scenes = list(filter(None, ds_scenes))\n",
    "    date_scenes = list(filter(None, date_scenes))\n",
    "\n",
    "    for i, ds in enumerate(ds_scenes):\n",
    "        if ds[\"ndvi\"].shape[0] == 0 or ds[\"ndvi\"].shape[1] == 0:\n",
    "            del ds_scenes[i]\n",
    "            del date_scenes[i]\n",
    "\n",
    "    #ds_concat_max = xarray.concat([ds_scene.to_array(name=\"vegetation index\", dim=\"index\") for ds_scene in ds_scenes], dim=xarray.Variable('date', pd.to_datetime(date_scenes))).to_dataset(dim=\"index\").groupby(\"date.month\").max()\n",
    "    ds_concat_max = xarray.concat(ds_scenes, dim=xarray.Variable('date', pd.to_datetime(date_scenes))).groupby('date.month').max()\n",
    "\n",
    "    # RAM mgmt\n",
    "    del ds_scenes, date_scenes\n",
    "\n",
    "    return ds_concat_max\n",
    "\n",
    "def merge_year_scenes_by_tile(year: int):\n",
    "    \"\"\"merge scene file parts by tile to year vegetation index (still separated by tile)\"\"\"\n",
    "    month_files = {}\n",
    "    dates = {}\n",
    "    tiles = {}\n",
    "    \n",
    "    for file in os.listdir(f\"{BASE_DIR}/month\"):\n",
    "        # regex match using AOI from variable\n",
    "        m = re.match(\"\".join([AOI, \"\\_(\\d{2})\\_(\\d{4})\\_(\\d{2}\\w{3})\\.nc\"]), file)\n",
    "        \n",
    "        if m:\n",
    "            month = m.group(1)\n",
    "            y = m.group(2)\n",
    "            tile = m.group(3)\n",
    "            if y not in month_files:\n",
    "                month_files[y] = {}\n",
    "                dates[y] = {}\n",
    "                tiles[y] = {}\n",
    "\n",
    "                month_files[y][tile] = [f\"{BASE_DIR}/month/{file}\"]\n",
    "                dates[y][tile] = [f\"01-{month}-{y}\"]\n",
    "                tiles[y][tile] = [tile]\n",
    "            else:\n",
    "                if tile not in month_files[y]:\n",
    "                    month_files[y][tile] = [f\"{BASE_DIR}/month/{file}\"]\n",
    "                    dates[y][tile] = [f\"01-{month}-{y}\"]\n",
    "                    tiles[y][tile] = [tile]\n",
    "                else:\n",
    "                    month_files[y][tile].append(f\"{BASE_DIR}/month/{file}\")\n",
    "                    dates[y][tile].append(f\"01-{month}-{y}\")\n",
    "                    tiles[y][tile].append(tile)\n",
    "    \n",
    "    tile_datasets = []\n",
    "    for tile in month_files[year]:\n",
    "        tile_datasets.append(\n",
    "            xarray.concat(\n",
    "                [xarray.open_dataset(file, decode_coords=\"all\").squeeze(\"month\").drop(\"month\") for file in month_files[year][tile]], # squeeze month dimension before\n",
    "                dim=xarray.Variable('date', pd.to_datetime(dates[year][tile])) # concatenating datasets by date (month)\n",
    "            ).groupby(\"date.year\").max().expand_dims({\"tile\": tiles[year][tile]}).groupby(\"tile\").max()\n",
    "        )\n",
    "\n",
    "    ds = xarray.concat(tile_datasets, dim=\"tile\")\n",
    "\n",
    "    del tile_datasets\n",
    "\n",
    "    ds.to_netcdf(f\"{BASE_DIR}/year/{AOI}_{year}.nc\", 'w', engine='netcdf4')\n",
    "\n",
    "    del ds, month_files, dates, tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# months and years to loop through\n",
    "months = [f\"{month:02d}\" for month in range(5, 9)] # may to august\n",
    "years = [str(year) for year in range(2015, 2022)] # 2015 to 2021\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        # get scenes from planetary computer\n",
    "        search = get_scenes(month=month, year=year, bbox=BBOX_SEARCH)\n",
    "        # create pyStacItemCollection\n",
    "        pyStacItemCollection = search.get_all_items()\n",
    "        \n",
    "        items_list = np.array([item.to_dict() for item in pyStacItemCollection])\n",
    "        \n",
    "        if len(items_list) == 0:\n",
    "            print(f\"No scenes found for {month}-{year} ...\")\n",
    "            continue\n",
    "        else:\n",
    "            for _i, tile in enumerate(TILES_OF_INTEREST):\n",
    "                item_list_tile_part = list()\n",
    "                # identify scenes from same tile\n",
    "                for item_in_list in items_list:\n",
    "                    if tile in item_in_list[\"id\"]:\n",
    "                        item_list_tile_part.append(item_in_list)\n",
    "\n",
    "                print(\"-\"*50)\n",
    "                print(f\"Starting iteration for tile {tile} ({_i})\")\n",
    "                print(\"-\"*50)\n",
    "\n",
    "                # pystac to stacstac item\n",
    "                # necessary to use within intake_stac collection\n",
    "                stacStacItems = [Item(sentinel_item) for sentinel_item in item_list_tile_part]\n",
    "\n",
    "                # items to stac item collection\n",
    "                stacStacItemCollection = ItemCollection(stacStacItems)\n",
    "\n",
    "                # StacItemCollection to filter Catalog by Item Name\n",
    "                intakeStacItemCollection = intake_stac.catalog.StacItemCollection(stacStacItemCollection)\n",
    "\n",
    "                # get dataset (max index values)\n",
    "                ds = process_scenes(intakeStacItemCollection)\n",
    "                # export to nc file\n",
    "                ds.to_netcdf(f\"{BASE_DIR}/month/{AOI}_{month}_{year}_{tile}.nc\", 'w', engine='netcdf4')\n",
    "\n",
    "                del ds\n",
    "\n",
    "    print(\"Calculating max vegetation index for current year...\")\n",
    "    merge_year_scenes_by_tile(str(year))\n",
    "    \n",
    "    print(f\"Done ({year}) ...\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "724e6f39cdbf3b5e7001e4ddb41fea5ea8e778b88b5b3cf46118f48ff2eef77f"
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}